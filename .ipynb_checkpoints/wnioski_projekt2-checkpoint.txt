Metoda 1 - pełna analiza klasyfikatora k-Nearest Neighbors (k-NN) dla zbioru danych dotyczącego długości pobytu pacjenta w szpitalu, z zastosowaniem 5-krotnej walidacji krzyżowej (5-fold CV) i wartościami parametru k: 1, 3, 5 i 7.

Wyniki przedstawiają się następująco:

k = 1 → train accuracy = 1.000, test accuracy = 0.201

k = 3 → train accuracy = 0.852, test accuracy = 0.205

k = 5 → train accuracy = 0.603, test accuracy = 0.229

k = 7 → train accuracy = 0.539, test accuracy = 0.241

Z powyższych wyników wynika, że dla bardzo małych wartości k (szczególnie k = 1), model osiąga idealną skuteczność na danych treningowych (train_acc = 1.000), co jest typowym objawem silnego przeuczenia (overfittingu). Jednak dokładność na zbiorze testowym wynosi jedynie 20,1%, co oznacza bardzo słabą zdolność generalizacji — model „uczy się na pamięć” danych uczących, ale nie potrafi dobrze klasyfikować nowych przykładów.

Wraz ze wzrostem wartości k spada dokładność na zbiorze treningowym, co oznacza, że model jest mniej skomplikowany i bardziej ogólny (rośnie bias). Z drugiej strony, test accuracy systematycznie rośnie i osiąga najwyższy poziom (24,1%) dla k = 7. Jest to najlepszy rezultat wśród analizowanych wartości i świadczy o najlepszym balansie między niedouczeniem (bias) a nadmiernym dopasowaniem (variance).

Podsumowując: najlepsze rezultaty osiąga klasyfikator k-NN z k = 7. Wartość test_acc = 0.241 nie jest bardzo wysoka, co może oznaczać, że zbiór danych jest trudny (np. klasy mocno się mieszają), a cechy mogą nie być wystarczająco rozdzielcze. Aby poprawić wyniki, można rozważyć bardziej złożone modele (np. drzewa decyzyjne, sieci neuronowe) lub przeprowadzić inżynierię cech (feature engineering), np. przez redukcję wymiarowości lub tworzenie cech syntetycznych.

Metoda 2 - Zastosowano klasyfikator oparty na centroidach – czyli tzw. Nearest Centroid Classifier – i oceniono jego działanie przy użyciu 5-krotnej walidacji krzyżowej (5-fold CV) oraz czterech różnych metryk odległości:

Dla każdej klasy (np. długość pobytu pacjenta w szpitalu) obliczany jest średni punkt (centroid) w przestrzeni cech. Klasyfikacja nowej próbki polega na przypisaniu jej do najbliższego centroidu, mierząc odległość według zadanej metryki.

Wyniki dokładności dla każdej metryki:
Metryka	Dokładność treningowa (train_acc)	Dokładność testowa (test_acc)
Euclidean	0.059	0.058
Manhattan	0.059	0.058
Chebyshev	0.060	0.059
Cosine	0.053	0.051

Wszystkie metryki dają bardzo niskie wyniki – zaledwie ok. 5–6% trafności, czyli niewiele więcej niż losowe zgadywanie.

Najlepiej wypada Chebyshev, ale różnice są minimalne i statystycznie nieistotne.

Cosine similarity działa najgorzej — co oznacza, że kierunek wektora (ważny przy tej metryce) nie niesie wartościowych informacji w tych danych.

train_acc ≈ test_acc – model nie overfituje, ale po prostu nie potrafi dobrze dopasować się do danych.

Podejście Nearest Centroid jest zbyt proste, by poradzić sobie z danymi złożonymi, jak te dotyczące pobytów w szpitalu.

Przestrzeń cech jest najpewniej nieliniowa i złożona, więc granice decyzyjne oparte na centroidach (czyli liniowe, symetryczne wokół klasy) nie wystarczają.

Metoda 3 - W tej metodzie zbadano wpływ parametru var_smoothing, czyli:
małego dodatku dodawanego do wariancji cech, który zapobiega dzieleniu przez zero i niestabilnościom obliczeniowym (np. w cechach o zerowej wariancji), im większy var_smoothing, tym bardziej „wygładzamy” rozkłady Gaussa dla każdej cechy.

Wyniki:
var_smoothing	train_acc	test_acc
1e-09	0.369	0.359
1e-08	0.369	0.359
1e-07	0.369	0.359
1e-06	0.369	0.359

Niezależnie od wartości var_smoothing, dokładność modelu nie ulega zmianie.

To oznacza, że: Dane są już wystarczająco dobrze opisane wariancją, a wygładzenie ma znikomy wpływ, Różnice między klasami są „głębsze” niż to, co może uchwycić prosty model GNB.

Gaussian Naive Bayes jest bardzo szybki i lekki, ale zakłada niezależność cech, nie uwzględnia korelacji między zmiennymi i dopasowuje granice decyzyjne w oparciu tylko o średnie i wariancje.
Dane są prawdopodobnie zawierają cechy, które trudno dobrze opisać samym rozkładem Gaussa.
Brak zmian w wynikach nawet przy dużej rozpiętości var_smoothing sugeruje, że cechy nie mają zerowej wariancji (czyli nie są stałe), nie występują problemy numeryczne, które var_smoothing miałby łagodzić lub model nie jest wrażliwy na drobne korekty — co nie musi być złe, tylko mówi nam o jego ograniczeniu.

Metoda 3 wersja zaawanosowana - analiza klasyfikatora Gaussian Naive Bayes (GNB) z ręcznie zaimplementowanym PCA i ocena wpływ liczby głównych komponentów na skuteczność klasyfikacji.

W tym kodzie zredukowano wymiar danych — czyli zmniejszono liczbę cech (zmiennych), zachowując jak najwięcej informacji.
Założenie, że rozkład cech w każdej klasie jest normalny (Gaussa), a cechy są niezależne.
Przeprowadzono 5-krotną walidację krzyżową (5-fold CV) dla różnych liczby komponentów PCA.
5, 10, 15 oraz wszystkie dostępne (17 cech).

Wyniki klasyfikacji:
Liczba komponentów	Train accuracy	Test accuracy
5	0.288	0.286
10	0.323	0.313
15	0.361	0.352
17 (pełny wymiar)	0.362	0.350

Zbyt mała liczba komponentów (np. 5) powoduje znaczną utratę informacji:
test_acc spada do ok. 28,6%. Model nie ma wystarczających danych, by skutecznie odróżniać klasy.
10 komponentów daje już zauważalną poprawę:
test_acc = 31,3%.
Najlepsze wyniki uzyskano dla 15 komponentów:
train_acc = 36,1%, test_acc = 35,2%,
co oznacza dobry kompromis między jakością a prostotą modelu.
Użycie pełnego wymiaru (17 cech) nie przynosi dalszej poprawy, wręcz test_acc lekko spada:
co może wskazywać na pojawienie się szumu lub nadmiarowości cech.

Gaussian Naive Bayes w połączeniu z PCA to szybki i lekki model, który radzi sobie dobrze w klasyfikacji danych medycznych.
Najlepszy balans między złożonością a jakością uzyskano przy 15 komponentach PCA.
Model osiąga test accuracy na poziomie ~35%, co jest istotnie lepszym wynikiem niż metody wcześniejsze (centroidy, k-NN przy niskim k).
Podejście to jest również bardziej skalowalne do dużych zbiorów danych i dobrze współpracuje z dalszymi etapami przetwarzania (np. ensemble learning, selekcja cech).

Metoda 4 - W tej czwartej metodzie zaimplementowano od zera klasyfikator wieloklasowy typu Softmax Regression (czyli regresję logistyczną wieloklasową) i przetestowano jego skuteczność na danych rzeczywistych z użyciem 5-krotnej walidacji krzyżowej i różnych poziomów regularyzacji L2.

Zaimplementowano klasyfikator Softmax Regression oparty o regresję logistyczną w wersji dla wielu klas (poprzez funkcję softmax), uczony przy pomocy gradient descent z dodanym regularyzatorem L2 (λ ⋅ ||W||²), a następnie przetestowany przy różnych poziomach siły regularyzacji (reg).

Przetestowano 4 wartości parametru reg (regularyzacja L2):
0.0, 0.01, 0.1, 1.0

Wyniki klasyfikacji:
Wartość reg	Train accuracy	Test accuracy
0.00	0.207	0.207
0.01	0.200	0.200
0.10	0.173	0.172
1.00	0.198	0.198

Brak regularyzacji (reg = 0.0) daje najlepsze wyniki: model nie overfituje, czyli nie uczy się „na pamięć”, ale też nie uczy się zbyt dobrze — bo test_acc to tylko ~20,7%. Dodanie regularyzacji (L2) systematycznie obniża accuracy: lekkie wygładzanie (reg = 0.01) obniża skuteczność o ~0,7 punktu procentowego, silniejsza regularyzacja (reg = 0.1) powoduje underfitting — model traci zdolność do odróżniania klas.
Wysoka regularyzacja (reg = 1.0) tylko częściowo poprawia wyniki po silnym spadku, ale nie odzyskuje wcześniejszej skuteczności.

Softmax Regression tworzy liniowe granice decyzyjne pomiędzy klasami.
Dane są zapewne nieliniowo rozdzielne (klasy nie da się oddzielić prostą granicą) — dlatego model „nie wystarcza”.
Sam fakt, że model bez regularyzacji nie przeucza się, świadczy o tym, że jego „pojemność” jest i tak zbyt mała w stosunku do złożoności danych.
Test accuracy na poziomie ~20% oznacza, że model radzi sobie lepiej niż losowe zgadywanie, ale znacznie gorzej niż GNB (~36%) czy kNN dla większych wartości k (~24%).





