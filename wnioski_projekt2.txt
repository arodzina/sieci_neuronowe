Metoda 1 - pełna analiza klasyfikatora k-Nearest Neighbors (k-NN) dla zbioru danych dotyczącego długości pobytu pacjenta w szpitalu, z zastosowaniem 5-krotnej walidacji krzyżowej (5-fold CV) i wartościami parametru k: 1, 3, 5 i 7.

Wyniki przedstawiają się następująco:

k = 1 → train accuracy = 1.000, test accuracy = 0.201

k = 3 → train accuracy = 0.852, test accuracy = 0.205

k = 5 → train accuracy = 0.603, test accuracy = 0.229

k = 7 → train accuracy = 0.539, test accuracy = 0.241

Z powyższych wyników wynika, że dla bardzo małych wartości k (szczególnie k = 1), model osiąga idealną skuteczność na danych treningowych (train_acc = 1.000), co jest typowym objawem silnego przeuczenia (overfittingu). Jednak dokładność na zbiorze testowym wynosi jedynie 20,1%, co oznacza bardzo słabą zdolność generalizacji — model „uczy się na pamięć” danych uczących, ale nie potrafi dobrze klasyfikować nowych przykładów.

Wraz ze wzrostem wartości k spada dokładność na zbiorze treningowym, co oznacza, że model jest mniej skomplikowany i bardziej ogólny (rośnie bias). Z drugiej strony, test accuracy systematycznie rośnie i osiąga najwyższy poziom (24,1%) dla k = 7. Jest to najlepszy rezultat wśród analizowanych wartości i świadczy o najlepszym balansie między niedouczeniem (bias) a nadmiernym dopasowaniem (variance).

Podsumowując: najlepsze rezultaty osiąga klasyfikator k-NN z k = 7. Wartość test_acc = 0.241 nie jest bardzo wysoka, co może oznaczać, że zbiór danych jest trudny (np. klasy mocno się mieszają), a cechy mogą nie być wystarczająco rozdzielcze. Aby poprawić wyniki, można rozważyć bardziej złożone modele (np. drzewa decyzyjne, sieci neuronowe) lub przeprowadzić inżynierię cech (feature engineering), np. przez redukcję wymiarowości lub tworzenie cech syntetycznych.

