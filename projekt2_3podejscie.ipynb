{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-24T14:13:26.903813Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Wczytywanie i przygotowanie danych\n",
    "def load_and_prepare_data():\n",
    "    data = pd.read_csv('train_data.csv', sep=';')\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    categorical_columns = ['Hospital_type_code', 'City_Code_Hospital', 'Hospital_region_code',\n",
    "                          'Department', 'Ward_Type', 'Ward_Facility_Code', 'Type of Admission',\n",
    "                          'Severity of Illness', 'Age','Stay']\n",
    "    for col in categorical_columns:\n",
    "        if col in data.columns:\n",
    "            data[col] = le.fit_transform(data[col].astype(str))\n",
    "\n",
    "    data.drop(['case_id', 'patientid'], axis=1, errors='ignore', inplace=True)\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    if 'Stay' in data.columns:\n",
    "        stay_mapping = {'0-10': 0, '11-20': 1, '21-30': 2, '31-40': 3, '41-50': 4,\n",
    "                       '51-60': 5, '61-70': 6, '71-80': 7, '81-90': 8, '91-100': 9, 'More than 100 Days': 10}\n",
    "        data['Stay'] = data['Stay'].map(stay_mapping).fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "# KNN\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean', weight_type='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weight_type = weight_type\n",
    "\n",
    "    def calculate_distance(self, x1, x2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.linalg.norm(x1 - x2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            return 1 - (np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2)))\n",
    "        return np.linalg.norm(x1 - x2)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = np.array([self.calculate_distance(x, x_train) for x_train in self.X_train])\n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest = self.y_train[nearest_indices]\n",
    "\n",
    "            if self.weight_type == 'uniform':\n",
    "                prediction = Counter(k_nearest).most_common(1)[0][0]\n",
    "            else:\n",
    "                weights = 1 / (distances[nearest_indices] + 1e-8)\n",
    "                vote_weight = {}\n",
    "                for label, weight in zip(k_nearest, weights):\n",
    "                    vote_weight[label] = vote_weight.get(label, 0) + weight\n",
    "                prediction = max(vote_weight, key=vote_weight.get)\n",
    "\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Drzewo decyzyjne\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_leaf=1, criterion='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build(X, y)\n",
    "\n",
    "    def _build(self, X, y, depth=0):\n",
    "        if depth >= self.max_depth or len(set(y)) == 1 or len(y) < 2 * self.min_samples_leaf:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        best_feature, best_thresh, best_gain = None, None, -np.inf\n",
    "        impurity = self._impurity(y)\n",
    "\n",
    "        for f in range(X.shape[1]):\n",
    "            for t in np.unique(X[:, f]):\n",
    "                left, right = y[X[:, f] <= t], y[X[:, f] > t]\n",
    "                if len(left) < self.min_samples_leaf or len(right) < self.min_samples_leaf: continue\n",
    "                gain = impurity - len(left)/len(y)*self._impurity(left) - len(right)/len(y)*self._impurity(right)\n",
    "                if gain > best_gain:\n",
    "                    best_feature, best_thresh, best_gain = f, t, gain\n",
    "\n",
    "        if best_feature is None:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        mask = X[:, best_feature] <= best_thresh\n",
    "        return {\n",
    "            'f': best_feature,\n",
    "            't': best_thresh,\n",
    "            'l': self._build(X[mask], y[mask], depth+1),\n",
    "            'r': self._build(X[~mask], y[~mask], depth+1)\n",
    "        }\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        counts = np.bincount(y)\n",
    "        probs = counts / len(y)\n",
    "        if self.criterion == 'gini':\n",
    "            return 1 - np.sum(probs**2)\n",
    "        return -np.sum(p * np.log2(p + 1e-8) for p in probs if p > 0)\n",
    "\n",
    "    def _predict_one(self, x, tree):\n",
    "        while isinstance(tree, dict):\n",
    "            tree = tree['l'] if x[tree['f']] <= tree['t'] else tree['r']\n",
    "        return tree\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
    "\n",
    "# Naive Bayes\n",
    "class NaiveBayes:\n",
    "    def __init__(self, smoothing=1.0, distribution='gaussian'):\n",
    "        self.smoothing = smoothing\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = {c: np.mean(y == c) for c in self.classes}\n",
    "        self.stats = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            if self.distribution == 'gaussian':\n",
    "                self.stats[c] = (np.mean(X_c, axis=0), np.std(X_c, axis=0) + 1e-8)\n",
    "            else:\n",
    "                self.stats[c] = [{v: (np.sum(X_c[:, i] == v) + self.smoothing) /\n",
    "                                  (len(X_c) + self.smoothing * len(np.unique(X[:, i])))\n",
    "                                  for v in np.unique(X[:, i])}\n",
    "                                 for i in range(X.shape[1])]\n",
    "\n",
    "    def _likelihood(self, x, c):\n",
    "        if self.distribution == 'gaussian':\n",
    "            mu, sigma = self.stats[c]\n",
    "            return np.prod(1/(np.sqrt(2*np.pi)*sigma) * np.exp(-0.5*((x-mu)/sigma)**2))\n",
    "        else:\n",
    "            return np.prod([self.stats[c][i].get(x[i], self.smoothing / (len(self.stats[c][i]) + self.smoothing))\n",
    "                            for i in range(len(x))])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([max(self.classes, key=lambda c: self.priors[c] * self._likelihood(x, c)) for x in X])\n",
    "\n",
    "# Accuracy\n",
    "calculate_accuracy = lambda y_true, y_pred: np.mean(y_true == y_pred)\n",
    "\n",
    "# Testy\n",
    "\n",
    "def main():\n",
    "    data = load_and_prepare_data()\n",
    "    X = data.drop('Stay', axis=1).values\n",
    "    y = data['Stay'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    print(\"Szybki test trzech modeli:\")\n",
    "\n",
    "    knn = KNN(k=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(\"KNN Accuracy:\", calculate_accuracy(y_test, knn.predict(X_test)))\n",
    "\n",
    "    dt = DecisionTree(max_depth=5)\n",
    "    dt.fit(X_train, y_train)\n",
    "    print(\"Decision Tree Accuracy:\", calculate_accuracy(y_test, dt.predict(X_test)))\n",
    "\n",
    "    nb = NaiveBayes()\n",
    "    nb.fit(X_train, y_train)\n",
    "    print(\"Naive Bayes Accuracy:\", calculate_accuracy(y_test, nb.predict(X_test)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Szybki test trzech modeli:\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
